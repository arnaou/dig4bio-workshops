{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using Data Driven approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "In this notebook, we will consider a first principle Monod Kenetic model for cell growth.\n",
    "\n",
    "$$\n",
    "\\mu = \\mu_{max} * \\dfrac{S}{K_S + S} \\\\\n",
    "$$\n",
    "The balances are described as follows for the biomass:\n",
    "$$\n",
    "\\dfrac{dX}{dt} = \\mu * X \\\\\n",
    "$$\n",
    "And the substrate:\n",
    "$$\n",
    "\\dfrac{dS}{dt} = -\\dfrac{1}{Y_{xs}} * \\mu * X\n",
    "$$\n",
    "\n",
    "We will use this model to \"generate\" a dataset. We will assume the trye kenetics are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "To generate the data we first need to implement the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the model\n",
    "def monod_model(y,t, mu_max, Yxs, S0):\n",
    "    X, S = y\n",
    "    # define mu maxc\n",
    "\n",
    "    # define the derivatives\n",
    "    dXdt = 0\n",
    "    dSdt = 0\n",
    "    return [dXdt, dSdt] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For generating the data, we will use the following parameters\n",
    "\n",
    "| Parameter     | Value | Unit \t| Info                       |\n",
    "|---\t        |---\t|---\t|---                         |\n",
    "| $\\mu_{max}$  \t|  0.5 \t|   \t| maximum growth rate        |\n",
    "| $K_S \t        |  0.2 \t|   \t| half-saturation constant   |\n",
    "| $Y_{XS}$      |  0.4 \t|   \t| Yield coefficient          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate a range of initial conditions where $X_0 \\in [0.1, 0.3] $ and $S_0 \\in [1.0, 5.0]$. the simulation time is $t \\in [0, 10]$ (dont generate too many time steps, e.g. 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range of X01 and S0\n",
    "\n",
    "# define the time range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform data generation, we will sample uniformly from the ranges of $X_0$ and $S_0$.\n",
    "Solve th model. To add some stochasticity, we add some white noise. The nouse is charachterised by a the following distribution\n",
    "$N(\\mu=0, \\sigma=0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# make a loop\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sample):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# random initialize X0 and S0\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# store the results\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mt\u001b[49m)):\n\u001b[0;32m     16\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m: t[i],\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX0\u001b[39m\u001b[38;5;124m'\u001b[39m: X0,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m                                 μmax, Ks, Yxs, S0)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     24\u001b[0m         })\n",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "# define sample size\n",
    "n_sample = 100\n",
    "# unitialize list for data\n",
    "data = []\n",
    "# make a loop\n",
    "\n",
    "for _ in range(n_sample):\n",
    "    # random initialize X0 and S0\n",
    "\n",
    "    # solve the ode\n",
    "\n",
    "    # add noise\n",
    "\n",
    "    # store the results\n",
    "    for i in range(len(t)):\n",
    "        data.append({\n",
    "            't': t[i],\n",
    "            'X0': X0,\n",
    "            'S0': S0,\n",
    "            'X': max(0, X_noisy[i]),  # ensure non-negative\n",
    "            'S': max(0, S_noisy[i]),\n",
    "            'dXdt': monod_model([X_noisy[i], S_noisy[i]], t[i], \n",
    "                                μmax, Ks, Yxs, S0)[0]\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "The result should be made better presantable and converted into an easier format for preprocessing. Fllow the intructions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# convert data into a dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# prepare the features and target columns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[feature_columns]\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdXdt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# convert data into a dataframe\n",
    "\n",
    "# prepare the features and target columns\n",
    "feature_columns = ['t', 'X0', 'S0', 'X', 'S']\n",
    "X = df[feature_columns]\n",
    "y = df['dXdt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ML related preprocessing should include:\n",
    "* splitting\n",
    "* scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into bins\n",
    "\n",
    "\n",
    "# scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part select an ML model of your own choosing + a multilayer perceptron (MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models (for MLP, start out with the scikit-learn implementation)\n",
    "\n",
    "\n",
    "# train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained model, we can perform predictions. calculate various meryics of intrest and make the following plots\n",
    "* parity plot\n",
    "* error plot\n",
    "* prediction plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make parity plot\n",
    "\n",
    "# make error distribution plots\n",
    "\n",
    "# make prediction plot (growth trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Optimization\n",
    "\n",
    "Despite the fact that we dont have a mechanistic model and if the accuracy of the ML based model is sufficient, we can perform process optimization.\n",
    "Here, the obkective is to dtermine the necessairy initial consition in order to obtain a target biomass of 1.0 .\n",
    "\n",
    "A naive optimization will be done through grid search e.i. perform equidistant sampling of the initial condition and evaluate the final biomass concentration. Select the conditions providing the closes results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search over initial conditions\n",
    "\n",
    "# perform prediction for each instance\n",
    "\n",
    "# evaluate the closeness to the target\n",
    "\n",
    "# selec the best initial condition\n",
    "#  \n",
    "import numpy as np\n",
    "x = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimbio",
   "language": "python",
   "name": "aimbio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}