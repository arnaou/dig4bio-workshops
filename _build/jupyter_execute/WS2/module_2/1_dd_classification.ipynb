{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Data Driven Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "In this exercice, we will work with a dataset provided [here](https://www.kaggle.com/datasets/eddardd/continuous-stirred-tank-reactor-domain-adaptation). The aim is to perform fault diagnosis on a CSTR based on the measured signals.\n",
    "\n",
    "This datasets contains a set of simulations of a known benchmark in the fault diagnosis for chemical processes community, i.e., the Continuous Stirred Tank Reactor. This system carries an exothermic reaction A -> B, and a feedback loop for controlling the reactor's temperature. There are 7 measured variables.\n",
    "These variables are:\n",
    "\n",
    "* Concentration of A in the inlet flow,\n",
    "* Temperature of the inlet flow,\n",
    "* Temperature of the inlet coolant flow,\n",
    "* Coolant flow-rate,\n",
    "* Concentration of B in the outlet flow,\n",
    "* Temperature of the outlet flow,\n",
    "* Temperature of the outlet coolant flow.\n",
    "\n",
    "The goal is to predict a set of 12 faults from these 7 variables, measured throughout 200 minutes, at a 1 minute rate.\n",
    "Additional information on the faults can be found in {cite}`montesuma2021, montesuma2022cross`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploartory data Analysis\n",
    "\n",
    "The first step is to perform eploratory data analysis (EDA). This includes:\n",
    "* loading the data\n",
    "* convert to a suitable format\n",
    "* inspect the dataset (size, content)\n",
    "* clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zeroes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import necessairy packages (hint: numpy, sk-learn, matplotlib, etc.)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeroes\u001b[49m(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\aimbio\\lib\\site-packages\\numpy\\__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'zeroes'"
     ]
    }
   ],
   "source": [
    "# import necessairy packages (hint: numpy, sk-learn, matplotlib, etc.)\n",
    "import numpy as np\n",
    "\n",
    "print(np.zeroes(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset (hint....numpy)\n",
    "\n",
    "# convert to pandas dataframe (much nicer visuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the dataset (hint: show the top 10 rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the last 4 columns contain the following data:\n",
    "* Column 1400 refers to the Fault.\n",
    "* Column 1401 refers to the domain level\n",
    "* Column 1402 refers to the noise level\n",
    "* Column 1403 refers to the reaction order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data e.g. fault_label=df.iloc[:,-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the parameter noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the reaction order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate how these uniques values are associated in each domain, is there some exlusivity?\n",
    "\n",
    "#for domain in np.unique(domain_label):\n",
    "#    domain_parameters = np.where(domain_label == domain)[0]\n",
    "#    print(f'The domain {domain} has a noise level of {np.unique(parameter_noise[domain_parameters]).item()} and a reaction order of {np.unique(reaction_order[domain_parameters]).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate a function for evaluating various classification model\n",
    "\n",
    "#def predictions(classifier, X_train, y_train, X_test, y_test, model_name):\n",
    "#    classifier.fit(X_train, y_train)\n",
    "#    print(classifier.score(X_test, y_test))\n",
    "\n",
    "#    cm = confusion_matrix(classifier.predict(X_test), y_test)\n",
    "#    sns.heatmap(cm, annot=True, cmap='viridis')\n",
    "#    plt.title(f'Confusion matrix for {model_name}')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the current data, train and validate the following models:\n",
    "* SVC\n",
    "* DecisionTree\n",
    "* RF\n",
    "* XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "#print('SVC')\n",
    "#predictions(SVC(random_state=2207, probability=True), X_train, y_train, X_val, y_val, model_name='SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance\n",
    "Inspect the data again, have you noticed anything?\n",
    "are all variable of the same scale?\n",
    "If not, then scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data (hint: StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the models. how is the accuracy compared to previousely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimentionality Reduction\n",
    "A total of 1400 features are used. A question would be, is that really necessairy?\n",
    "Try to use PCA to reduce the number of features.\n",
    "and hpow much reduction is acceptable (see scree tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA (e.g. with variance threshhold of 0.956)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the threshold and select the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puhsing performance even further (extra)\n",
    "the models used so far relied on the default hyperparameters.\n",
    "Investigate the documentation of one model and create a grid search.\n",
    "Find the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice:\n",
    "Thanks to XXX and XXXX for contributing to the development of the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimbio",
   "language": "python",
   "name": "aimbio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}