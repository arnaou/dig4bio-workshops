{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Data Driven Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "In this exercice, we will work with a dataset provided [here](https://www.kaggle.com/datasets/eddardd/continuous-stirred-tank-reactor-domain-adaptation). The aim is to perform fault diagnosis on a CSTR based on the measured signals.\n",
    "\n",
    "This datasets contains a set of simulations of a known benchmark in the fault diagnosis for chemical processes community, i.e., the Continuous Stirred Tank Reactor. This system carries an exothermic reaction A -> B, and a feedback loop for controlling the reactor's temperature. There are 7 measured variables.\n",
    "These variables are:\n",
    "\n",
    "* Concentration of A in the inlet flow,\n",
    "* Temperature of the inlet flow,\n",
    "* Temperature of the inlet coolant flow,\n",
    "* Coolant flow-rate,\n",
    "* Concentration of B in the outlet flow,\n",
    "* Temperature of the outlet flow,\n",
    "* Temperature of the outlet coolant flow.\n",
    "\n",
    "The goal is to predict a set of 12 faults from these 7 variables, measured throughout 200 minutes, at a 1 minute rate.\n",
    "Additional information on the faults can be found in {cite}`montesuma2021, montesuma2022cross`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploartory data Analysis\n",
    "\n",
    "The first step is to perform eploratory data analysis (EDA). This includes:\n",
    "* loading the data\n",
    "* convert to a suitable format\n",
    "* inspect the dataset (size, content)\n",
    "* clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessairy packages (hint: numpy, sk-learn, matplotlib, etc.)\n",
    "import numpy as np\n",
    "\n",
    "print(np.zeroes(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset (hint....numpy)\n",
    "\n",
    "# convert to pandas dataframe (much nicer visuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the dataset (hint: show the top 10 rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the last 4 columns contain the following data:\n",
    "* Column 1400 refers to the Fault.\n",
    "* Column 1401 refers to the domain level\n",
    "* Column 1402 refers to the noise level\n",
    "* Column 1403 refers to the reaction order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data e.g. fault_label=df.iloc[:,-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the parameter noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the uniqueness of the reaction order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate how these uniques values are associated in each domain, is there some exlusivity?\n",
    "\n",
    "#for domain in np.unique(domain_label):\n",
    "#    domain_parameters = np.where(domain_label == domain)[0]\n",
    "#    print(f'The domain {domain} has a noise level of {np.unique(parameter_noise[domain_parameters]).item()} and a reaction order of {np.unique(reaction_order[domain_parameters]).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate a function for evaluating various classification model\n",
    "\n",
    "#def predictions(classifier, X_train, y_train, X_test, y_test, model_name):\n",
    "#    classifier.fit(X_train, y_train)\n",
    "#    print(classifier.score(X_test, y_test))\n",
    "\n",
    "#    cm = confusion_matrix(classifier.predict(X_test), y_test)\n",
    "#    sns.heatmap(cm, annot=True, cmap='viridis')\n",
    "#    plt.title(f'Confusion matrix for {model_name}')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the current data, train and validate the following models:\n",
    "* SVC\n",
    "* DecisionTree\n",
    "* RF\n",
    "* XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "#print('SVC')\n",
    "#predictions(SVC(random_state=2207, probability=True), X_train, y_train, X_val, y_val, model_name='SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance\n",
    "Inspect the data again, have you noticed anything?\n",
    "are all variable of the same scale?\n",
    "If not, then scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data (hint: StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the models. how is the accuracy compared to previousely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimentionality Reduction\n",
    "A total of 1400 features are used. A question would be, is that really necessairy?\n",
    "Try to use PCA to reduce the number of features.\n",
    "and hpow much reduction is acceptable (see scree tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA (e.g. with variance threshhold of 0.956)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the threshold and select the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puhsing performance even further (extra)\n",
    "the models used so far relied on the default hyperparameters.\n",
    "Investigate the documentation of one model and create a grid search.\n",
    "Find the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice:\n",
    "Thanks to XXX and XXXX for contributing to the development of the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimbio",
   "language": "python",
   "name": "aimbio"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
